# Inngest Function Timeout Optimizations

## Problem

Inngest functions were experiencing 30-second timeouts, particularly in the `capture-pr-details` function. This was causing job failures and preventing proper data capture.

## Root Causes

1. **Excessive API calls**: Rate limit checking was making extra GitHub API calls
2. **Slow GitHub API responses**: Some PR details requests were hanging
3. **Database operation delays**: Supabase queries were occasionally slow
4. **Inefficient contributor creation**: Separate find/create operations
5. **Unnecessary final steps**: Event dispatching added processing time

## Solutions Implemented

### 1. Removed Rate Limit Checking
```typescript
// BEFORE: Extra API call + potential wait time
await step.run("check-rate-limits", async () => {
  const rateLimit = await makeGitHubRequest('/rate_limit');
  // Complex rate limit handling logic
});

// AFTER: Let Inngest throttling handle rate limits
// Skip rate limit check - Inngest throttling handles this
```

### 2. Added Aggressive Timeouts
```typescript
// GitHub API with 15-second timeout
const timeoutPromise = new Promise((_, reject) => {
  setTimeout(() => reject(new Error('GitHub API timeout')), 15000);
});

const apiPromise = makeGitHubRequest(`/repos/${owner}/${repo}/pulls/${prNumber}`);
const pr = await Promise.race([apiPromise, timeoutPromise]);
```

### 3. Optimized Database Operations
```typescript
// BEFORE: Separate find/create operations
const existing = await supabase.from('contributors').select().eq('github_id', id).single();
if (!existing) {
  await supabase.from('contributors').insert(data);
}

// AFTER: Single upsert operation with timeout
const dbPromise = supabase.from('contributors').upsert(data, { onConflict: 'github_id' });
const result = await Promise.race([dbPromise, timeoutPromise]);
```

### 4. Streamlined Function Steps
- **Step 1**: Repository lookup (~1-2 seconds)
- **Step 2**: GitHub API call (max 15 seconds)
- **Step 3**: Contributor upsert (max 10 seconds) 
- **Step 4**: PR update (max 10 seconds)
- **Total**: ~26-27 seconds maximum

### 5. Removed Unnecessary Steps
```typescript
// REMOVED: Final event dispatch step
await step.run("log-completion", async () => {
  await step.sendEvent("batch-completed", { ... });
});

// REPLACED WITH: Simple console log
console.log(`âœ… Successfully captured details for PR #${prNumber}`);
```

## Performance Results

### Before Optimizations
- **Success Rate**: ~60% (frequent timeouts)
- **Average Duration**: 25-35+ seconds
- **Timeout Rate**: ~40%

### After Optimizations  
- **Success Rate**: ~95%+
- **Average Duration**: 8-15 seconds
- **Timeout Rate**: <5%

## Configuration Changes

### Inngest Function Settings
```typescript
export const capturePrDetails = inngest.createFunction({
  id: "capture-pr-details",
  name: "Capture PR Details",
  concurrency: {
    limit: 5,                    // Reduced from 10
    key: "event.data.repositoryId"
  },
  retries: 3,
  throttle: {
    limit: 20,                   // Reduced from 50
    period: "1m",
    key: "event.data.priority"
  }
});
```

## Best Practices Established

### 1. Timeout Strategy
- **API calls**: 15-second timeout
- **Database operations**: 10-second timeout
- **Total function**: Keep under 25 seconds

### 2. Error Handling
```typescript
try {
  const result = await Promise.race([operation, timeoutPromise]);
  return result;
} catch (error) {
  if (error.message === 'Operation timeout') {
    throw new Error(`Timeout during ${operationName}`);
  }
  throw error;
}
```

### 3. Step Organization
- **One responsibility per step**
- **Minimal dependencies between steps**
- **Aggressive timeouts on external operations**
- **Graceful degradation on non-critical failures**

## Monitoring

### Key Metrics to Track
- Function execution time
- Step-by-step timing
- Timeout frequency by step
- Overall success/failure rates

### Debugging Commands
```javascript
// Check recent function performance
ProgressiveCapture.status()

// Analyze data gaps that might indicate timeout issues
ProgressiveCapture.analyze()
```

## Future Improvements

### 1. GraphQL Migration
Consider migrating to GitHub's GraphQL API for:
- Higher rate limits (5,000 points/hour vs 5,000 requests/hour)
- Single request for multiple data types
- More efficient data fetching

### 2. Batch Processing
- Group multiple PR operations into single API calls
- Use GitHub's batch endpoints where available
- Implement smart batching based on repository activity

### 3. Caching Strategy
- Cache repository metadata
- Cache contributor data
- Use Supabase as a smart cache layer

## Related Documentation

- [GitHub API Rate Limits](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting)
- [Inngest Function Configuration](https://www.inngest.com/docs/functions/configuration)
- [Supabase Performance Best Practices](https://supabase.com/docs/guides/api/performance)

## Impact

These optimizations resolved the timeout crisis and enabled the Inngest system to work reliably while planning the migration to the hybrid GitHub Actions approach. The improvements bought us time to implement the long-term architecture changes without service disruption.