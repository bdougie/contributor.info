#!/usr/bin/env node

/**
 * Clean up seed data from local database
 * Removes data that was generated by the seed script
 */

import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

// Load environment variables
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
dotenv.config({ path: join(__dirname, '../../.env.local') });
dotenv.config({ path: join(__dirname, '../../.env') });

// Configuration
const SUPABASE_URL = process.env.VITE_SUPABASE_URL || 'http://localhost:54321';
const SUPABASE_ANON_KEY = process.env.VITE_SUPABASE_ANON_KEY;

if (!SUPABASE_ANON_KEY) {
  console.error('âŒ Missing Supabase configuration!');
  console.error('Run: npm run env:local');
  process.exit(1);
}

// Initialize Supabase client
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

/**
 * Clean seed data
 */
async function cleanSeedData() {
  console.log('ğŸ§¹ Cleaning Seed Data');
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');
  
  const confirmation = process.argv[2];
  if (confirmation !== '--confirm') {
    console.log('âš ï¸  This will remove all seed data from your local database!');
    console.log('');
    console.log('To confirm, run:');
    console.log('  npm run db:seed:clean -- --confirm');
    console.log('');
    return;
  }
  
  try {
    // Get seed generation jobs to identify seed repositories
    const { data: seedJobs, error: jobError } = await supabase
      .from('progressive_capture_jobs')
      .select('repository_id, metadata')
      .eq('job_type', 'seed_data_capture');
    
    if (jobError) {
      console.error('âŒ Failed to fetch seed jobs:', jobError.message);
      return;
    }
    
    if (!seedJobs || seedJobs.length === 0) {
      console.log('No seed data jobs found. Nothing to clean.');
      return;
    }
    
    // Extract unique repository IDs
    const repositoryIds = [...new Set(seedJobs.map(job => job.repository_id).filter(Boolean))];
    
    console.log(`Found ${repositoryIds.length} seeded repositories to clean`);
    console.log('');
    
    let deletedCounts = {
      comments: 0,
      reviews: 0,
      pull_requests: 0,
      repositories: 0,
      jobs: 0
    };
    
    // Delete in order to respect foreign key constraints
    
    // 1. Delete comments
    const { count: commentCount, error: commentError } = await supabase
      .from('comments')
      .delete()
      .in('repository_id', repositoryIds)
      .select('*', { count: 'exact', head: true });
    
    if (commentError) {
      console.error(`âš ï¸  Failed to delete comments: ${commentError.message}`);
    } else {
      deletedCounts.comments = commentCount || 0;
      console.log(`  âœ… Deleted ${deletedCounts.comments} comments`);
    }
    
    // 2. Delete reviews (need to get PR IDs first)
    const { data: prs } = await supabase
      .from('pull_requests')
      .select('github_id')
      .in('repository_id', repositoryIds);
    
    if (prs && prs.length > 0) {
      const prIds = prs.map(pr => pr.github_id);
      const { count: reviewCount, error: reviewError } = await supabase
        .from('reviews')
        .delete()
        .in('pull_request_id', prIds)
        .select('*', { count: 'exact', head: true });
      
      if (reviewError) {
        console.error(`âš ï¸  Failed to delete reviews: ${reviewError.message}`);
      } else {
        deletedCounts.reviews = reviewCount || 0;
        console.log(`  âœ… Deleted ${deletedCounts.reviews} reviews`);
      }
    }
    
    // 3. Delete pull requests
    const { count: prCount, error: prError } = await supabase
      .from('pull_requests')
      .delete()
      .in('repository_id', repositoryIds)
      .select('*', { count: 'exact', head: true });
    
    if (prError) {
      console.error(`âš ï¸  Failed to delete pull requests: ${prError.message}`);
    } else {
      deletedCounts.pull_requests = prCount || 0;
      console.log(`  âœ… Deleted ${deletedCounts.pull_requests} pull requests`);
    }
    
    // 4. Delete repositories
    const { count: repoCount, error: repoError } = await supabase
      .from('repositories')
      .delete()
      .in('id', repositoryIds)
      .select('*', { count: 'exact', head: true });
    
    if (repoError) {
      console.error(`âš ï¸  Failed to delete repositories: ${repoError.message}`);
    } else {
      deletedCounts.repositories = repoCount || 0;
      console.log(`  âœ… Deleted ${deletedCounts.repositories} repositories`);
    }
    
    // 5. Delete seed jobs
    const { count: jobCount, error: deleteJobError } = await supabase
      .from('progressive_capture_jobs')
      .delete()
      .eq('job_type', 'seed_data_capture')
      .select('*', { count: 'exact', head: true });
    
    if (deleteJobError) {
      console.error(`âš ï¸  Failed to delete jobs: ${deleteJobError.message}`);
    } else {
      deletedCounts.jobs = jobCount || 0;
      console.log(`  âœ… Deleted ${deletedCounts.jobs} seed jobs`);
    }
    
    console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log('ğŸ¯ Summary:');
    console.log(`  â€¢ Comments: ${deletedCounts.comments}`);
    console.log(`  â€¢ Reviews: ${deletedCounts.reviews}`);
    console.log(`  â€¢ Pull Requests: ${deletedCounts.pull_requests}`);
    console.log(`  â€¢ Repositories: ${deletedCounts.repositories}`);
    console.log(`  â€¢ Jobs: ${deletedCounts.jobs}`);
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log('\nâœ¨ Seed data cleaned successfully!');
    console.log('Run `npm run db:seed` to generate fresh seed data.');
    
  } catch (error) {
    console.error('\nâŒ Error cleaning seed data:', error);
    process.exit(1);
  }
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  cleanSeedData().catch(console.error);
}